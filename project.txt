Letâ€™s build a full blueprint for your Bachelorâ€™s thesis project:
ğŸ“ â€œReal-Time Speech Translation in Online Conferencesâ€
so you know exactly what to research, build, and deliver.

ğŸ§© PART 1 â€” Research To-Do (Before Implementation)

Your goal here is to collect and analyze existing tools + methods so you can justify your design to the supervisor.

ğŸ”¹ A. Research Objectives

Find answers to:

Speech-to-Text (STT):

Which ASR (Automatic Speech Recognition) models handle English â†” Slovak best?

Compare: OpenAI Whisper, Vosk, Google Speech API, Azure STT, Mozilla DeepSpeech.

Machine Translation (MT):

Whatâ€™s the best low-latency translator for your target languages?

Compare: Google Translate API, DeepL API, Helsinki-NLP (Opus-MT).

Text-to-Speech (TTS):

Compare: Coqui TTS, ElevenLabs, eSpeak, Google TTS.

Real-time streaming + pipeline management:

Can the pipeline process data in chunks (streaming ASR â†’ MT â†’ TTS)?

Latency per module?

Integration options:

Which open-source conferencing systems (Jitsi, Janus, Mediasoup) allow audio injection or subtitle overlays?

ğŸ”¹ B. Research Tasks
Step	Task	Output
1	Analyze existing tools & APIs (STT, MT, TTS)	Comparison table
2	Measure their latency and quality on sample audio	Report (accuracy, delay, CPU use)
3	Study integration options (Jitsi SDK, WebRTC streams, OBS audio routing)	Integration strategy
4	Define final architecture (components, data flow, delay target)	Diagram + short explanation
5	Write a Research Summary Report (2â€“3 pages)	For supervisor approval
âš™ï¸ PART 2 â€” Development Pipeline (Implementation Phase)

Once the research is approved, this becomes your README + workflow for building the prototype.

ğŸ§± 1. System Overview

Goal:
Translate live speech between English â†” Slovak in near real time during an online meeting.

Architecture:

Audio Input (mic / stream)
      â†“
Speech-to-Text (Whisper)
      â†“
Text Translation (DeepL / Opus-MT)
      â†“
Text-to-Speech (Coqui / ElevenLabs)
      â†“
Output Audio / Subtitle Display

ğŸ§© 2. Tech Stack
Component	Tool / Library	Language
Audio capture & playback	PyAudio / sounddevice	Python
Speech-to-Text	Whisper API or local Whisper model	Python
Translation	DeepL API / Opus-MT (HuggingFace)	Python
Text-to-Speech	Coqui TTS or pyttsx3	Python
UI / display	Streamlit / Electron / Web app with Flask	Python + JS
Real-time management	asyncio / threading / WebSockets	Python
Conference Integration	Jitsi Meet SDK (Web API overlay)	JS/HTML frontend
ğŸªœ 3. Development Stages
Phase 1 â€” Local Pipeline Prototype

Goal: Build a working speech â†’ translated text â†’ speech pipeline locally.

Steps:

Record sample audio.

Transcribe using Whisper.

Translate using API.

Convert translated text back to speech.

Measure total delay (target < 2â€“3 seconds).

Phase 2 â€” Real-Time Audio Stream

Goal: Process live microphone input in chunks.

Use sounddevice or PyAudio for streaming.

Feed short buffers to Whisper for incremental transcription.

Stream translated text or generated voice.

Phase 3 â€” User Interface

Goal: Provide a way to:

Start/stop translation.

Show subtitles in real time.

(Optional) Play synthesized translated speech.

Frameworks:

Streamlit (simple, fast)

or Electron/HTML overlay for embedding in Jitsi.

Phase 4 â€” Integration & Testing

Goal: Integrate your translator into a conference simulation.

Option 1: Use Jitsi Meet or Janus with custom overlay.

Option 2: Use OBS or WebRTC test room to simulate multi-user call.

Test:

End-to-end latency

Accuracy (qualitative)

CPU/GPU performance

ğŸ“ 4. Repository Structure (README layout)
/real-time-speech-translation
â”‚
â”œâ”€â”€ /research
â”‚   â”œâ”€â”€ asr_comparison.md
â”‚   â”œâ”€â”€ translation_comparison.md
â”‚   â”œâ”€â”€ tts_comparison.md
â”‚   â””â”€â”€ architecture_diagram.png
â”‚
â”œâ”€â”€ /src
â”‚   â”œâ”€â”€ audio_input.py
â”‚   â”œâ”€â”€ stt_whisper.py
â”‚   â”œâ”€â”€ translate.py
â”‚   â”œâ”€â”€ tts_output.py
â”‚   â”œâ”€â”€ main_pipeline.py
â”‚   â””â”€â”€ ui_app.py
â”‚
â”œâ”€â”€ /tests
â”‚   â”œâ”€â”€ latency_test.py
â”‚   â”œâ”€â”€ accuracy_test.py
â”‚   â””â”€â”€ integration_test.py
â”‚
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ README.md
â””â”€â”€ thesis_report_outline.md

ğŸ“˜ README.md (template content)

Title: Real-Time Speech Translation in Online Conference
Description: Prototype system translating English â†” Slovak speech in real time using modern AI models.

ğŸ§  Features

Live speech-to-text transcription (Whisper)

Neural translation (DeepL / Opus-MT)

Real-time subtitle display

(Optional) Speech synthesis of translation

Designed for integration into online conference tools

âš™ï¸ Architecture

Include diagram + module explanations (as above)

ğŸ’» Installation
git clone https://github.com/username/real-time-translation
cd real-time-translation
pip install -r requirements.txt

ğŸš€ Usage
python main_pipeline.py

ğŸ§ª Testing
python tests/latency_test.py

ğŸ“Š Results

Average delay: ~1.8s

STT accuracy: 94% (Whisper medium)

Translation accuracy: good for English â†” Slovak short sentences

ğŸ“ PART 3 â€” Research Paper / Presentation

To present to your supervisor and later for your thesis defense:

Paper Outline (5â€“7 pages)

Introduction: Problem, motivation (language barriers in online meetings)

Theoretical background:

Speech recognition, translation, synthesis

Real-time streaming challenges

State of the art:

Overview of Whisper, DeepL, Coqui, etc.

System design:

Architecture, chosen tools, diagram

Implementation:

Code structure, algorithms

Evaluation:

Latency, accuracy, possible improvements

Conclusion & future work:

Adding new languages, better TTS voice quality, full integration into real platforms.

Presentation (for supervisor / defense)

7â€“10 slides:

Title + your name

Problem & motivation

Current technologies overview

Proposed architecture

Demo / screenshots

Results & evaluation

Next steps / possible applications

âœ… Next Step

You can now:

Begin research tasks (make a comparison table of ASR/MT/TTS tools).

Present that to your supervisor for confirmation.

Then start coding the Phase 1 prototype (offline version).